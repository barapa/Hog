\documentclass{book}
\usepackage{fancyhdr, graphicx, multicol}

\title{\huge \textbf{The Hog Programming Language}}
\author{Jason Halpern \\ jrh2170 \\ Testing/Validation
        \and Samuel Messing \\ sbm2158 \\ Project Manager
        \and Benjamin Rapaport \\ bar2150 \\ System Architect
        \and Kurry Tran \\ klt2127 \\ System Integrator
        \and Paul Tylkin \\ pt2302 \\ Language Guru}

\begin{document}
\maketitle

\tableofcontents

\chapter{Introduction}
\label{chap:intro}

\section{Taming the Elephant}
\label{sec:elephant}

As data sets have grown in size, so have the complexities of dealing with them.
For instance, consider wanting to generate counts for all the words in
\emph{War and Peace} by means of distributed computation. Writing in Java and
using Hadoop MapReduce (TM),\footnote{\texttt{http://hadoop.apache.org/}} a
simple solution takes over 50 lines of code, as the programmer is required to
specify intermediate objects not directly related to the desired computation,
but required simply to get Hadoop to function properly. Our goal is to produce
a language that can express the same computation in about 10 lines.


Hog is a \textbf{data-oriented}, \textbf{high-level}, scripting language for
creating MapReduce\cite{dean:2004} programs. Used alongside Hadoop, Hog enables
users to efficiently carry out \textbf{distributed} computation. Hadoop
MapReduce is an open-source framework for carrying out distributed computation,
which is especially useful for working with large data sets. While it is
possible to write code to carry out computations with Hadoop directly, the
framework requires users to specify low-level details that are often irrelevant
to their desired goal.

By building a scripting language on top of Hadoop, we aim to simplify the
process. Built around a \textbf{simple} and highly \textbf{readable} syntax,
Hog will let users focus on \emph{what} computations they want done, and not
\emph{how} they want to do them.  Hog takes care of all the low-level details
required to run computations on Hadoop’s distributed network. All a user needs
to do is tell Hog the location of their valid Hadoop instance, and Hog will do
the rest. 

\subsection{Data-Oriented}
\label{sub:data-oriented}

Hog is a powerful language that allows for the efficient handling of
structured, unstructured and semi-structured data. Specifically, Hog simplifies
the process of writing programs to handle the distributed processing of
data-intensive applications. Programmers using Hog only have to express the
steps for processing the data in the Map and Reduce functions without having to
be concerned with relations and the constraints imposed by a traditional
database schema. Hog also provides control flow structures to manipulate this
data. In addition, Hog frees a programmer from having to write each step in a
data processing task since many of those low-level processing details are
handled by the language and the system.

Hog uses Hadoop MapReduce (TM), an open-source MapReduce framework written in
Java. Hadoop’s run time system takes care of the details of partitioning the
input data, scheduling the program’s execution across machines, counteracting
machine failures, and managing inter-machine communication. Hadoop also
distributes data to machines and tries to collocate chunks of data with the
nodes that need it, therefore maximizing data locality and giving good
performance.

\subsection{Simple}
\label{sub:simple}

To write a simple word count program in Java using the Hadoop framework
requires over 59 lines of
code.\footnote{\texttt{http://hadoop.apache.org/common/docs/current/mapred\_tutorial.html}}
The same program written in Hog requires just 10 lines. The discrepancy comes
from the fact that Hog takes care of the low-level details required to
correctly communicate and interact with the Hadoop framework. This allows users
to enhance the expressive potential of their programs, without sacrificing
power. All that Hog requires a user to do is specify the location of their
valid Hadoop instance, write a map function to process a segment of data, write
a reduce function to combine the results, and Hog takes care of the rest.

\chapter{Tutorial}
\label{chap:tutor}

Use your updated tutorial.

\chapter{Language Reference Manual}
\label{chap:LRM}

Use your update LRM.

\chapter{Project Plan}
\label{chap:plan}

Written by Samuel Messing (sbm2158).

\section{Development Process}

The scope of the Hog programming language was ambitious from the start. Our
stated goal was to create a general-purpose scripting language which made
carrying out distributed computation simple and intuitive. As such, from the
beginning we were interested in ways to make the implementation of the language
as simple as possible. The following goals were identified early on:

\begin{itemize}
\item make the build system as simple as possible,
\item make the logic of our individual modules as similar as possible,
\item document everything,
\item use a distributed version control system,
\item write verbose and informative log statements.
\end{itemize}

Focusing on these goals throughout the development enabled use to work concurrently
on different aspects of the compiler and maintain a codebase that was both readable
and easy to understand.  

\subsection{Simplicity of Build System}

As project manager, I worked early on with both the System Architect (Ben) and
the System Integrator (Kurry) to come up with a build system that was simple and
easily extensible. After trying a few different options, we decided on Ant,
a build system similar to Make, specialized for the Java programming language.
Another advantage of going with Ant is that both JFlex and Cup, the frameworks
we used to construct the lexer and parser, respectively, have native Ant support.
Identifying and implementing our build system early on enabled us to move quickly
and write code that we were sure worked across all of our machines. 

\subsection{Similarity of Modules}

Throughout the project, I worked very closely with the System Architect (Ben) to
develop and build common data structures that could be used across all of our
code. The abstract syntax tree was made in a generic enough way so that all
of our different tree walks could use the exact same tree class, without having
to support and debug different implementations of the same interface or abstract
parent class.  

Personally, I also developed our Types class, which was a static class that
contained several convenience methods for handling types across the entirety
of the compiler. These methods include type checking, type conversion and
as well as additional functionality required for internal functionality. I
set out to write the class as early as possible so that both elements of
the frontend and the backend could make use of it. Simplifying and unifying how
different modules handled the same information enabled everyone on the team to
read each other's code qand quickly understand how it functioned.

\subsection{Document Everything}

One of the most undersold parts of Java is it's well thought out documentation
schema (JavaDocs). Early on I realized that in order for us to be able to work
semi-independently on different modules we would need to have a robust set of
documentation. By using JavaDoc instead of regular comments, we were able to
generate HTML documentation, which more clearly provides an overview of the entire
architecture of our compiler, and allowed everyone on our team to work quickly and
respond to updated classes appropriately.

One of the largest challeneges in this project was developing a set of node classes
for our abstract syntax trees that captured the right granularity of information,
without beeing too complex that handling corner cases became intractable. Our
System Architect (Ben) found a great tool that generated UML diagrams for our
class hierarchies, which in concert with our JavaDocs helped to make development
as simple and efficient as possible. 

\subsection{Distributed Version Control}

As soon as our team was formed I created a git repository on
Github.com\footnote{\texttt{http://www.github.com/smessing/Hog}} for use by the
team. One of the first things we discussed as a team was what workflow pattern
we wanted to use throughout the course of the project. Very quickly we decided
on a continuous-build pattern, where the main branch of our git repository 
(master) was reserved for compiling, tested, and finalized code. Any classes
that were currently in development existed in separate branches, and were only
merged into master after sufficient amount of testing. Each programmer maintained
their own branch for development. If two or more programmers were working on the
same class, a new, shared branch was created. By being conservative about what
code was merged into the master branch, we were able to work independently, without
fear that someone else's work would be interrupted by leaving our individual code
in an unfinished state. 

\subsection{Verbose Logging}

Another advantage of programming in Java is the robust and sophisticated logging
libraries available to the programmer. Around the same time that the build system
was developed, the System Architect (Ben) investigated several different logging
libraries and wrote a tutorial for the rest of us on how to use it. The logging
library supported several levels of log statements, FINEST, FINER, FINE, INFO,
WARNING and SEVERE (from most verbose to least). We decided that FINEST and FINER
were to be used strictly for debugging, while FINE was to be used to document 
normal behavior, at a level of detail that was concise enough for all developers
to look at, but still too verbose for the user. INFO, WARNING and SEVERE were
reserved for statements that the user would see. By identifying and keeping
to these log levels early on, we were able to quickly identify bugs and 
inefficient or errant behavior. 

\section{Roles and Responsibilities}

\begin{itemize}
\item Ben, System Architect 
\begin{quotation}
\noindent Ben's major responsibilities included developing the fundamental data structures
used by the compiler, working out the different elements of the compiler and
how they interrelate, and developing the symbol table.   
\end{quotation}
\item Jason, Testing/Validation
\begin{quotation}
\noindent Jason's major responsibilities included testing all of the elements of our compiler,
and working on the aspects of the compiler related to type checking, and developing
the symbol table.
\end{quotation}
\item Kurry, System Integrator
\begin{quotation}
\noindent Kurry's major responsibilties included developing a clean interface between
Hog and Hadoop and working on the Hog wrapper program that builds, compiles and
runs Hog source programs.  
\end{quotation}
\item Paul, Language Guru
\begin{quotation}
\noindent Paul's major responsibility was determining the syntax and semantics of our
language, and developing the semantic analyzer.
\end{quotation}
\item Sam, Project Manager
\begin{quotation}
\noindent As project manager, my major responsibilities included setting project deadlines,
assigning work, and making sure that we met our goals. I was also responsible
for developing the classes to translate Hog programs into Java programs. 
\end{quotation}
\end{itemize}

\section{Hog's Developer Style Sheet}

We made use of the standard Java style guide, including such conventions as camel
case, verbs for functions and method names, and hierachical object classes. For
formatting, we used Eclipse's auto-format feature to keep our code looking as
consistent as possible. 

\section{Project Timeline}

\begin{itemize}
\item[] January
\begin{quotation}
\noindent Developed several potential ideas for languages. Met with Aho and decided on
implementing Hog, a MapReduce language.   
\end{quotation}
\item[] February
\begin{quotation}
\noindent Worked on the White Paper for our language, developed both the goals of our language
and the overall ``feel'' (simple, minimal boilerplate code, easy-to-read syntax).
Started to sketch out overall compiler architecture, and decided on frameworks
(JFlex for the lexer, CUP for parser, Hadoop framework for executing distributed computation, and Java as target language) and development environments (Eclipse, Git, Github, \LaTeX $\,$ for documentation). 
\end{quotation}
\item[] March
\begin{quotation}
\noindent Wrote the language reference manual and tutorial for our language. 
Developed the build system (Ant for compiling compiler code, Make for running
the compiler on Hog source programs), implemented and tested the parser and lexer,
and developed the fundamental data structures (abstract syntax tree, node classes).
\end{quotation}
\item[] April
\begin{quotation}
\noindent Implemented tree walking algorithms to populate the symbol table, perform
type checking, perform semantic analysis and generate Java source code. Wrote
tests for the walkers. 
\end{quotation}
\item[] May
\begin{quotation}
\noindent Refactored code and worked on documentation. Developed more tests and
worked on fixing bugs. 
\end{quotation}
\end{itemize}

\section{Project Log}

\begin{itemize}
\item[] January
\begin{itemize}
\item[] Week of January 22nd
\begin{itemize}
\item Met to discuss language ideas.
\end{itemize}
\item[] Week of January 29th
\begin{itemize}
\item Decided on Hog, and Java as implementation language.
\end{itemize}
\end{itemize}
\item[] February
\begin{itemize}
\item[] Week of Feburary 5th
\begin{itemize}
\item Decided on Hadoop as the framework for executing distributed computation.
\item Decided on JFlex framework for implementing the lexer.
\item Decided on CUP framework for implementing the parser. 
\end{itemize}
\item[] Week of February 12th
\begin{itemize}
\item Discussed and figured out development environment (Java, Ant, Eclipse, Git).
\item Started working on white paper.
\end{itemize}
\item[] Week of February 19th
\begin{itemize}
\item Started git repository.
\item Finished white paper.
\end{itemize}
\item[] Week of February 26th 
\begin{itemize}
\item Began the language reference manual (LRM). 
\end{itemize}
\end{itemize}
\item[] March
\begin{itemize}
\item[] Week of March 4th
\begin{itemize}
\item Started Eclipse project.
\item Worked on LRM and tutorial.
\end{itemize} % march 4th
\item[] Week of March 11th
\begin{itemize}
\item Began developing the Hog grammar.
\item Worked on LRM and tutorial.
\item Started working on wrapper program functionality (program that runs the
Hog compiler to compile source programs).
\end{itemize} % march 11th
\item[] Week of March 18th
\begin{itemize}
\item Finished the Hog grammar.
\item Finished the tutorial and LRM.
\item Began developing the lexer.
\end{itemize}
\item[] Week of March 25th
\begin{itemize}
\item Took the week off to study for the midterm.
\end{itemize}
\end{itemize} % march
\item[] April
\begin{itemize}
\item[] Week of April 1st
\begin{itemize}
\item Worked on the lexer.
\item Started developing the abstract syntax tree and node classes.
\item Started developing the parser.
\item Implemented developer build system.
\end{itemize} 
\item[] Week of April 8th
\begin{itemize}
\item Developed ConsoleLexer class for development and testing of lexer. 
\item Developed lexer JUnit tests. 
\item Finished abstract syntax tree, including iterators for post- and pre-order 
traversals.
\item Developed mock classes for testing.
\end{itemize}
\item[] Week of April 15th
\begin{itemize}
\item Further development/refinement of node classes.
\item Developed more semantic actions for parser, mainly to construct node classes.
\item Parsed our first program! 
\end{itemize}
\item[] Week of April 22nd
\begin{itemize}
\item Developed/implemented basic type functionality.
\item Further refinement of the grammar.
\item Implemented logging details. 
\item Refinement of node classes and ASTs.
\item Started tree walking algorithms (identified the visitor pattern as our
common design pattern for tree walks).
\item Begain developing symbol table class.
\end{itemize}
\item[] Week of April 29th
\begin{itemize}
\item Finished implementation of symbol table class.
\item Finished type checking / symbol table population walks.
\item Implemented java source generator.
\item Implemented tests for walkers and parser. 
\item Finished compiler.
\end{itemize}
\end{itemize} % april
\end{itemize} % log


\chapter{Language Evolution}
\label{chap:evo}

To be written by Paul.

\begin{itemize}
\item Describe how the language evolved during the implementation and what steps were used to try to maintain the good attributes of the original language proposal.
\item Describe the compiler tools used to create the compiler components.
\item Describe what unusual libraries are used in the compiler.
\item Describe what steps were taken to keep the LRM and the compiler consistent.
\end{itemize}

\chapter{Translator Architecture}
\label{chap:trans}

To be written by Ben.

\begin{itemize}
\item Show the architectural block diagram of translator.
\item Describe the interfaces between the modules.
\item State which modules were written by which team members.
\end{itemize}

\chapter{Development and Run-Time Environment}
\label{chap:environ}

To be written by Kurry.

\begin{itemize}
\item Describe the software development environment used to create the compiler.
\item Show the makefile used to create and test the compiler during development.
\item Describe the run-time environment for the compiler.
\end{itemize}

\chapter{Test Plan}
\label{chap:test}

To be written by Jason.

\begin{itemize}
\item Describe the test methodology used during development.
\item Show programs used to test your translator.
\end{itemize}

\chapter{Conclusions}
\label{chap:concl}

\section{Lessons Learned}
\label{sec:lessons}

\subsection{Jason's Lessons}
\label{sub:jasons-lessons}

To be written by Jason.

\subsection{Sam's Lessons}
\label{sub:sams-lessons}

To be written by Sam.

\subsection{Ben's Lessons}
\label{sub:bens-lessons}

To be written by Ben.

\subsection{Kurry's Lessons}
\label{sub:kurrys-lessons}

To be wrtten by Kurry.

\subsection{Paul's Lessons}
\label{sub:pauls-lessons}

To be written by Paul.

\section{Advice for Other Teams}

Don't take this class.

\section{Suggestions for Instructor}

Don't teach this class.

\appendix

\chapter{Code Listing}

Include a listing of the complete source code with identification of who wrote
which module of the compiler. This listing does not have to be included in the
paper copy of the final report.

\nocite{*}
\bibliographystyle{acm}
\bibliography{references}

\end{document}
